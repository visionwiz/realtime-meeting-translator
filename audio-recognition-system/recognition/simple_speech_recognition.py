import os
import queue
import threading
import time
from typing import Callable
from google.cloud import speech_v2
from google.api_core.client_options import ClientOptions
from google.protobuf import duration_pb2  # Voice Activity Timeoutç”¨

class SimpleStreamingSpeechRecognition:
    """Google Cloud Speech-to-Text V2 + chirp_2ã®çœŸã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè£…ï¼ˆå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå®Œå…¨æº–æ‹ ï¼‰"""
    
    def __init__(self, language_code="ja-JP", result_callback=None, 
                 project_id=None, region="global", verbose=False):
        # åŸºæœ¬è¨­å®š
        self.language_code = language_code
        self.result_callback = result_callback
        self.verbose = verbose
        
        # çµŒéæ™‚é–“ãƒ‡ãƒãƒƒã‚°ç”¨
        self.start_time = None
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¥ãƒ¼ï¼ˆThreadSafeãªQueueä½¿ç”¨ï¼‰
        self.audio_queue = queue.Queue()
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆ¶å¾¡
        self.streaming_active = False
        self.streaming_start_time = None
        self.max_streaming_duration = 300  # 5åˆ†åˆ¶é™
        
        # ãƒ­ã‚°å‡ºåŠ›é »åº¦åˆ¶å¾¡ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šï¼‰
        self.last_audio_log_time = 0
        self.last_response_log_time = 0
        self.audio_log_interval = 1.0  # 1ç§’é–“éš”
        self.response_count = 0
        
        # Google Cloud Speech V2 ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        self.project_id = project_id or os.getenv('GOOGLE_CLOUD_PROJECT')
        self.region = region
        
        if not self.project_id:
            raise ValueError("Google Cloud ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°GOOGLE_CLOUD_PROJECTã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
            
        self.client = speech_v2.SpeechClient()
        
        print(f"ğŸŒ©ï¸ Simple Google Cloud Speech-to-Text V2 + long åˆæœŸåŒ–ï¼ˆä¼šè­°ç¿»è¨³å‘ã‘VADè¨­å®šï¼‰")
        print(f"   ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {self.project_id}")
        print(f"   ãƒªãƒ¼ã‚¸ãƒ§ãƒ³: {self.region}")
        print(f"   è¨€èª: {language_code}")
        print(f"   Voice Activity Detection: æœ‰åŠ¹ï¼ˆé–‹å§‹10ç§’å¾…æ©Ÿã€çµ‚äº†3ç§’æ¤œå‡ºï¼‰- ãƒ†ã‚¹ãƒˆç”¨è¨­å®š")
        if not self.verbose:
            print("   ãƒ­ã‚°ãƒ¢ãƒ¼ãƒ‰: ç°¡æ½”è¡¨ç¤ºï¼ˆæœ€çµ‚çµæœã®ã¿è¡¨ç¤ºã€è©³ç´°ãƒ­ã‚°ã¯verbose=Trueã§æœ‰åŠ¹åŒ–ï¼‰")
    
    def add_audio_data(self, audio_data: bytes):
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ """
        if self.streaming_active:
            self.audio_queue.put(audio_data)
            
            # ãƒ­ã‚°å‡ºåŠ›é »åº¦åˆ¶å¾¡ï¼ˆverboseãƒ¢ãƒ¼ãƒ‰ã®ã¿è©³ç´°è¡¨ç¤ºï¼‰
            if self.verbose:
                current_time = time.time()
                if (current_time - self.last_audio_log_time) > self.audio_log_interval:
                    print(f"ğŸ¤ éŸ³å£°ãƒ‡ãƒ¼ã‚¿è¿½åŠ : {len(audio_data)} bytesï¼ˆã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚º: {self.audio_queue.qsize()}ï¼‰")
                    self.last_audio_log_time = current_time
    
    def start_streaming_recognition(self):
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜é–‹å§‹ï¼ˆãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°å®Ÿè¡Œ - å†æ¥ç¶šæ©Ÿèƒ½å¯¾å¿œï¼‰"""
        self.streaming_active = True
        self.streaming_start_time = time.time()
        self.start_time = self.streaming_start_time  # çµŒéæ™‚é–“ãƒ‡ãƒãƒƒã‚°ç”¨
        
        print("ğŸŒ©ï¸ çœŸã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜é–‹å§‹ï¼ˆå…¬å¼æº–æ‹ ç‰ˆ + Voice Activity Detectionï¼‰")
        print(f"â° é–‹å§‹æ™‚åˆ»: {time.strftime('%H:%M:%S', time.localtime(self.start_time))}")
        
        # ç›´æ¥å®Ÿè¡Œï¼ˆãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰- å†æ¥ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œ
        self._run_streaming_recognition()
    
    def _get_elapsed_time(self):
        """é–‹å§‹ã‹ã‚‰ã®çµŒéæ™‚é–“ã‚’å–å¾—ï¼ˆç§’ï¼‰"""
        if self.start_time:
            return time.time() - self.start_time
        return 0
    
    def _format_elapsed_time(self, elapsed_seconds):
        """çµŒéæ™‚é–“ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        return f"{elapsed_seconds:.1f}ç§’"
    
    def _audio_generator(self):
        """å…¬å¼æº–æ‹ ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼ˆç¶™ç¶šçš„ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰"""
        if self.verbose:
            print("ğŸµ éŸ³å£°ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼é–‹å§‹")
        
        while self.streaming_active:
            try:
                # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ™‚é–“åˆ¶é™ãƒã‚§ãƒƒã‚¯
                if self.streaming_start_time and (time.time() - self.streaming_start_time) > self.max_streaming_duration:
                    elapsed = self._get_elapsed_time()
                    print(f"â° ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ™‚é–“åˆ¶é™ï¼ˆ5åˆ†ï¼‰ã«é”ã—ã¾ã—ãŸ [{self._format_elapsed_time(elapsed)}]")
                    break
                
                # ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°å–å¾—ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ã‚’ç¢ºä¿
                audio_data = self.audio_queue.get(timeout=1.0)
                if audio_data is None:  # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
                    elapsed = self._get_elapsed_time()
                    print(f"ğŸ›‘ éŸ³å£°ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼çµ‚äº†ã‚·ã‚°ãƒŠãƒ«å—ä¿¡ [{self._format_elapsed_time(elapsed)}]")
                    break
                    
                if self.verbose:
                    print(f"ğŸ¶ éŸ³å£°ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: {len(audio_data)} bytes")
                yield audio_data
                
            except queue.Empty:
                # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã¯ç¶™ç¶šï¼ˆéŸ³å£°ãŒãªã„é–“ã‚‚æ¥ç¶šç¶­æŒï¼‰
                if self.verbose:
                    print("â° éŸ³å£°å¾…æ©Ÿä¸­...")
                continue
        
        # çµ‚äº†ç†ç”±ã‚’ãƒ­ã‚°å‡ºåŠ›
        elapsed = self._get_elapsed_time()
        if not self.streaming_active:
            print(f"ğŸ›‘ éŸ³å£°ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼çµ‚äº†: streaming_active=False [{self._format_elapsed_time(elapsed)}]")
        else:
            print(f"ğŸ›‘ éŸ³å£°ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼çµ‚äº†: ãã®ä»–ã®ç†ç”± [{self._format_elapsed_time(elapsed)}]")
        
        if self.verbose:
            print("ğŸµ éŸ³å£°ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼çµ‚äº†")
    
    def _run_streaming_recognition(self):
        """çœŸã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜å‡¦ç†ï¼ˆå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå®Œå…¨æº–æ‹  + Voice Activity Detectionï¼‰"""
        try:
            # Recognizer ãƒªã‚½ãƒ¼ã‚¹ãƒ‘ã‚¹
            recognizer_name = f"projects/{self.project_id}/locations/{self.region}/recognizers/_"
            if self.verbose:
                print(f"ğŸ”§ Recognizer: {recognizer_name}")
            
            # èªè­˜è¨­å®šï¼ˆæ˜ç¤ºçš„PCMãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæŒ‡å®šï¼‰
            recognition_config = speech_v2.types.RecognitionConfig(
                explicit_decoding_config=speech_v2.types.ExplicitDecodingConfig(
                    encoding=speech_v2.types.ExplicitDecodingConfig.AudioEncoding.LINEAR16,
                    sample_rate_hertz=16000,
                    audio_channel_count=1,
                ),
                language_codes=[self.language_code],
                model="long",
                features=speech_v2.types.RecognitionFeatures(
                    enable_automatic_punctuation=True,
                    enable_word_time_offsets=True,
                )
            )
            
            # Voice Activity Detectionè¨­å®šï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼š10ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰
            speech_start_timeout = duration_pb2.Duration(seconds=10)  # 10ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆå†æ¥ç¶šãƒ†ã‚¹ãƒˆç”¨ï¼‰
            speech_end_timeout = duration_pb2.Duration(seconds=3)     # éŸ³å£°çµ‚äº†ã‹ã‚‰3ç§’ã§is_finalé€ä¿¡
            voice_activity_timeout = speech_v2.types.StreamingRecognitionFeatures.VoiceActivityTimeout(
                speech_start_timeout=speech_start_timeout,
                speech_end_timeout=speech_end_timeout
            )
            
            streaming_config = speech_v2.types.StreamingRecognitionConfig(
                config=recognition_config,
                streaming_features=speech_v2.types.StreamingRecognitionFeatures(
                    interim_results=True,  # ä¸­é–“çµæœã‚‚å—ä¿¡
                    enable_voice_activity_events=True,  # Voice Activity Eventsæœ‰åŠ¹åŒ–
                    voice_activity_timeout=voice_activity_timeout  # éŸ³å£°çµ‚äº†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
                )
            )
            
            # å…¬å¼æº–æ‹ ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆç”Ÿæˆé–¢æ•°
            def generate_requests():
                """å…¬å¼æº–æ‹ ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼"""
                # æœ€åˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆè¨­å®šã®ã¿ï¼‰
                print("ğŸ“¤ è¨­å®šãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ï¼ˆVoice Activity Detectionæœ‰åŠ¹ï¼‰")
                yield speech_v2.types.StreamingRecognizeRequest(
                    recognizer=recognizer_name,
                    streaming_config=streaming_config
                )
                
                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆç¶™ç¶šçš„ï¼‰
                print("ğŸµ éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹")
                for audio_data in self._audio_generator():
                    if self.verbose:
                        print(f"ğŸ“¤ éŸ³å£°ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡: {len(audio_data)} bytes")
                    yield speech_v2.types.StreamingRecognizeRequest(
                        audio=audio_data
                    )
                
                if self.verbose:
                    print("ğŸ“¤ ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼çµ‚äº†")
            
            print("ğŸš€ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜å®Ÿè¡Œé–‹å§‹...")
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜å®Ÿè¡Œï¼ˆå…¬å¼æº–æ‹ ï¼‰
            response_stream = self.client.streaming_recognize(
                requests=generate_requests()
            )
            
            print("ğŸ“¨ ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†é–‹å§‹...")
            self.response_count = 0
            
            try:
                for response in response_stream:
                    self.response_count += 1
                    
                    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡ãƒ­ã‚°ï¼ˆverboseãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰
                    if self.verbose:
                        current_time = time.time()
                        if (current_time - self.last_response_log_time) > 1.0:
                            print(f"ğŸ“¥ ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡ #{self.response_count}")
                            self.last_response_log_time = current_time
                    
                    # Voice Activity Eventså‡¦ç†ï¼ˆGoogleå…¬å¼æ©Ÿèƒ½ï¼‰
                    if hasattr(response, 'speech_event_type') and response.speech_event_type:
                        elapsed = self._get_elapsed_time()
                        if response.speech_event_type == speech_v2.types.StreamingRecognizeResponse.SpeechEventType.SPEECH_ACTIVITY_BEGIN:
                            print(f"ğŸ—£ï¸ éŸ³å£°é–‹å§‹æ¤œå‡º [{self._format_elapsed_time(elapsed)}]")
                        elif response.speech_event_type == speech_v2.types.StreamingRecognizeResponse.SpeechEventType.SPEECH_ACTIVITY_END:
                            print(f"ğŸ¤« éŸ³å£°çµ‚äº†æ¤œå‡ºï¼ˆæœ€çµ‚çµæœé€ä¿¡æº–å‚™ï¼‰ [{self._format_elapsed_time(elapsed)}]")
                    
                    if hasattr(response, 'results') and response.results:
                        for i, result in enumerate(response.results):
                            if self.verbose:
                                print(f"ğŸ¯ çµæœ #{i}: is_final={result.is_final}")
                            
                            if hasattr(result, 'alternatives') and result.alternatives:
                                # æœ€åˆã®ä»£æ›¿çµæœã‚’ä½¿ç”¨
                                transcript = result.alternatives[0].transcript
                                confidence = getattr(result.alternatives[0], 'confidence', 0.0)
                                is_final = result.is_final
                                
                                if transcript.strip():
                                    # æœ€çµ‚çµæœã®ã¿è¡¨ç¤ºï¼ˆé€”ä¸­çµæœã¯éè¡¨ç¤ºï¼‰
                                    if is_final:
                                        elapsed = self._get_elapsed_time()
                                        print(f"\nğŸ¯ æœ€çµ‚çµæœ: {transcript}")
                                        print(f"   çµŒéæ™‚é–“: [{self._format_elapsed_time(elapsed)}]")
                                        if self.verbose:
                                            print(f"   ä¿¡é ¼åº¦: {confidence:.2f}")
                                    elif self.verbose:
                                        # verboseãƒ¢ãƒ¼ãƒ‰ã§ã®ã¿é€”ä¸­çµæœã‚’è¡¨ç¤º
                                        print(f"ğŸ“ é€”ä¸­çµæœ: {transcript}")
                                    
                                    # çµæœã‚’ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã«é€ä¿¡ï¼ˆãƒ­ã‚°è¡¨ç¤ºã¯ã—ãªã„ï¼‰
                                    if self.result_callback:
                                        try:
                                            self.result_callback(transcript, confidence, is_final)
                                        except Exception as callback_error:
                                            print(f"\nâŒ ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é€ä¿¡ã‚¨ãƒ©ãƒ¼: {callback_error}")
                                elif self.verbose:
                                    print("ğŸ“ ç©ºã®transcript")
                            elif self.verbose:
                                print("ğŸ“ alternatives ãªã—")
                    elif self.verbose:
                        print("ğŸ“­ results ãªã—")
                        # ã‚¨ãƒ©ãƒ¼æƒ…å ±ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                        if hasattr(response, 'error'):
                            print(f"âŒ ã‚¨ãƒ©ãƒ¼æƒ…å ±: {response.error}")
                
                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¹ãƒˆãƒªãƒ¼ãƒ æ­£å¸¸çµ‚äº†
                elapsed = self._get_elapsed_time()
                print(f"ğŸ“¨ ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¹ãƒˆãƒªãƒ¼ãƒ æ­£å¸¸çµ‚äº† [{self._format_elapsed_time(elapsed)}]")
            
            except Exception as response_error:
                elapsed = self._get_elapsed_time()
                print(f"âŒ ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†ä¸­ã‚¨ãƒ©ãƒ¼ [{self._format_elapsed_time(elapsed)}]: {response_error}")
                if self.verbose:
                    import traceback
                    traceback.print_exc()
                            
        except Exception as e:
            print(f"âš ï¸ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
            if self.verbose:
                import traceback
                traceback.print_exc()
        finally:
            self.streaming_active = False
            elapsed = self._get_elapsed_time()
            print(f"ğŸŒ©ï¸ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜çµ‚äº† [{self._format_elapsed_time(elapsed)}]")
    
    def stop_recognition(self):
        """èªè­˜åœæ­¢"""
        self.streaming_active = False
        self.audio_queue.put(None)  # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
        print("ğŸ›‘ èªè­˜åœæ­¢è¦æ±‚é€ä¿¡")
    
    def _reset_for_reconnection(self):
        """å†æ¥ç¶šç”¨ã®çŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆ"""
        # ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢ï¼ˆå¤ã„éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼‰
        while not self.audio_queue.empty():
            try:
                self.audio_queue.get_nowait()
            except queue.Empty:
                break
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ãƒªã‚»ãƒƒãƒˆ
        self.last_audio_log_time = 0
        self.last_response_log_time = 0
        self.response_count = 0
        
        if self.verbose:
            print("ğŸ”„ éŸ³å£°èªè­˜çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆå®Œäº†")
    
    def is_active(self):
        """èªè­˜ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‹ã©ã†ã‹"""
        return self.streaming_active 