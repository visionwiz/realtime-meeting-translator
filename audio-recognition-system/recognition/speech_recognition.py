import sys
import os
import datetime
import queue
import wave
import time
import numpy as np
import pyaudio
from language_config import LanguageConfig
import io
import threading
from concurrent.futures import ThreadPoolExecutor

# Google Cloud Speech-to-Text V2é–¢é€£
from google.cloud import speech_v2
from google.api_core.client_options import ClientOptions
import google.auth
from google.auth.transport.requests import Request


class GoogleCloudSpeechV2Recognition:
    """Google Cloud Speech-to-Text API V2 + chirp_2ã‚’ä½¿ç”¨ã™ã‚‹éŸ³å£°èªè­˜ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config, processing_queue, translation_queue, args, lang_config):
        self.config = config
        self.processing_queue = processing_queue
        self.translation_queue = translation_queue
        self.args = args
        self.lang_config = lang_config
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š
        self.project_id = os.getenv("GOOGLE_CLOUD_PROJECT", "meeting-voice-bridge")
        self.region = "asia-southeast1"
        
        # Google Cloud Speech V2ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        self.client_options = ClientOptions(
            api_endpoint=f"{self.region}-speech.googleapis.com"
        )
        self.client = speech_v2.SpeechClient(client_options=self.client_options)
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨ã‚­ãƒ¥ãƒ¼ã¨ãƒ•ãƒ©ã‚°
        self.streaming_queue = queue.Queue()
        self.streaming_active = False
        
        print(f"ğŸŒ©ï¸ Google Cloud Speech-to-Text V2 + chirp_2 åˆæœŸåŒ–å®Œäº†")
        print(f"   ãƒªãƒ¼ã‚¸ãƒ§ãƒ³: {self.region}")
        print(f"   è¨€èª: {lang_config.get_source_language_code()}")
        print(f"   ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {self.project_id}")
    
    def run_recognition_thread(self):
        """éŸ³å£°èªè­˜ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰"""
        try:
            # Streamingã§chirp_2ã‚’ä½¿ç”¨
            self._run_streaming_recognition()
        except Exception as e:
            print(f"âš ï¸ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ¨™æº–ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            self._run_standard_recognition()
    
    def _run_streaming_recognition(self):
        """Google Cloud Speech V2 + chirp_2 ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜"""
        print("ğŸŒ©ï¸ Google Cloud Speech-to-Text V2 ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹")
        
        # Recognizer ãƒªã‚½ãƒ¼ã‚¹ãƒ‘ã‚¹
        recognizer_name = f"projects/{self.project_id}/locations/{self.region}/recognizers/_"
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®š
        streaming_config = speech_v2.types.StreamingRecognitionConfig(
            config=speech_v2.types.RecognitionConfig(
                auto_decoding_config=speech_v2.types.AutoDetectDecodingConfig(),
                language_codes=[self.lang_config.get_source_language_code()],
                model="chirp_2",
                features=speech_v2.types.RecognitionFeatures(
                    enable_automatic_punctuation=True,
                    enable_word_time_offsets=True,
                )
            ),
            streaming_features=speech_v2.types.StreamingRecognitionFeatures(
                interim_results=True
            )
        )
        
        # æœ€åˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆè¨­å®šã®ã¿ï¼‰
        def request_generator():
            # è¨­å®šãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            yield speech_v2.types.StreamingRecognizeRequest(
                recognizer=recognizer_name,
                streaming_config=streaming_config
            )
            
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            while self.streaming_active:
                try:
                    data = self.streaming_queue.get(timeout=1.0)
                    if data is None:  # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
                        break
                    yield speech_v2.types.StreamingRecognizeRequest(audio=data)
                except queue.Empty:
                    continue
        
        self.streaming_active = True
        
        try:
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜å®Ÿè¡Œ
            response_stream = self.client.streaming_recognize(request_generator())
            
            for response in response_stream:
                if response.results:
                    result = response.results[0]
                    if result.alternatives:
                        transcript = result.alternatives[0].transcript
                        confidence = getattr(result.alternatives[0], 'confidence', 0.0)
                        is_final = result.is_final
                        
                        if transcript.strip():
                            print(f"ğŸ¯ èªè­˜çµæœ ({confidence:.2f}): {transcript}")
                            
                            if is_final:
                                # æœ€çµ‚çµæœã‚’å‡¦ç†
                                self._process_final_result(transcript, confidence)
                            else:
                                # ä¸­é–“çµæœã‚’è¡¨ç¤º
                                print(f"  ğŸ“ é€”ä¸­çµæœ: {transcript}")
                                
        except Exception as e:
            print(f"âš ï¸ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
            self.streaming_active = False
    
    def _run_standard_recognition(self):
        """æ¨™æº–çš„ãªéŸ³å£°èªè­˜ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        print("ğŸ’¡ æ¨™æº–ã®èªè­˜è¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™")
        
        try:
            import speech_recognition as sr
            
            r = sr.Recognizer()
            mic = sr.Microphone(device_index=self.args.input_device)
            
            print("éŸ³å£°èªè­˜å¾…æ©Ÿä¸­...")
            
            with mic as source:
                r.adjust_for_ambient_noise(source)
            
            while True:
                try:
                    with mic as source:
                        audio = r.listen(source, timeout=1, phrase_time_limit=10)
                    
                    # Google Speech-to-Textã§èªè­˜
                    text = r.recognize_google(audio, language=self.lang_config.get_source_language_code())
                    
                    if text.strip():
                        print(f"ğŸ¯ èªè­˜çµæœ: {text}")
                        self._process_final_result(text, 0.8)
                        
                except sr.WaitTimeoutError:
                    pass
                except sr.UnknownValueError:
                    pass
                except sr.RequestError as e:
                    print(f"âš ï¸ èªè­˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                    time.sleep(1)
                except KeyboardInterrupt:
                    break
                    
        except ImportError:
            print("âš ï¸ SpeechRecognitionãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒä¸è¶³ã—ã¦ã„ã¾ã™")
    
    def _process_final_result(self, transcript, confidence):
        """æœ€çµ‚èªè­˜çµæœã®å‡¦ç†"""
        current_time = datetime.datetime.now()
        
        # èªè­˜çµæœã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
        recognition_data = {
            'timestamp': current_time,
            'text': transcript,
            'confidence': confidence,
            'speaker': self.args.speaker_name,
            'language': self.lang_config.get_source_language()
        }
        
        # ç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ ã®ãŸã‚ã«ã€æ–‡å­—åˆ—ã‚’æ—§ã‚·ã‚¹ãƒ†ãƒ å½¢å¼ã§é€ä¿¡
        self.translation_queue.put(transcript)
    
    def add_audio_data(self, audio_data):
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’èªè­˜ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ """
        if self.streaming_active:
            self.streaming_queue.put(audio_data)
    
    def stop_recognition(self):
        """éŸ³å£°èªè­˜ã‚’åœæ­¢"""
        self.streaming_active = False
        self.streaming_queue.put(None)  # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
        print("ğŸŒ©ï¸ Google Cloud Speech-to-Text V2 èªè­˜åœæ­¢")

# æ—¢å­˜ã®SpeechRecognitionã‚¯ãƒ©ã‚¹ã‚’ç½®ãæ›ãˆã‚‹
SpeechRecognition = GoogleCloudSpeechV2Recognition

