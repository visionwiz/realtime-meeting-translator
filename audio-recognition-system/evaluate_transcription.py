#!/usr/bin/env python3
"""
éŸ³å£°èªè­˜ç²¾åº¦è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ­£è§£ãƒ‡ãƒ¼ã‚¿ã¨éŸ³å£°èªè­˜çµæœã‚’æ¯”è¼ƒã—ã¦WERï¼ˆWord Error Rateï¼‰ã‚’è¨ˆç®—
"""

import re
import argparse
from pathlib import Path
from typing import List, Tuple
import difflib

def parse_transcript_file(file_path: str) -> List[Tuple[str, str]]:
    """
    éŸ³å£°èªè­˜çµæœãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯æ­£è§£ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ
    Returns: [(timestamp, text), ...]
    """
    results = []
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    current_timestamp = None
    for line in lines:
        line = line.strip()
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è¡Œã®æ¤œå‡º
        timestamp_match = re.match(r'\[(\d{2}:\d{2}:\d{2})\]', line)
        if timestamp_match:
            # æ­£è§£ãƒ‡ãƒ¼ã‚¿å½¢å¼: [HH:MM:SS] ãƒ†ã‚­ã‚¹ãƒˆ
            if ' ' in line:
                timestamp = timestamp_match.group(1)
                text = line[timestamp_match.end():].strip()
                results.append((timestamp, text))
            else:
                # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: [HH:MM:SS] ã ã‘ã®è¡Œ
                current_timestamp = timestamp_match.group(1)
        
        # éŸ³å£°èªè­˜çµæœã®æ¤œå‡º
        elif line.startswith('èªè­˜çµæœ(') and current_timestamp:
            # èªè­˜çµæœ(ja): ãƒ†ã‚­ã‚¹ãƒˆ å½¢å¼
            text_match = re.match(r'èªè­˜çµæœ\([^)]+\):\s*(.+)', line)
            if text_match:
                text = text_match.group(1)
                results.append((current_timestamp, text))
                current_timestamp = None
    
    return results

def normalize_text(text: str) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–ï¼ˆæ¯”è¼ƒç”¨ï¼‰"""
    # å¥èª­ç‚¹é™¤å»ã€ã‚¹ãƒšãƒ¼ã‚¹æ­£è¦åŒ–
    text = re.sub(r'[ã€‚ã€ï¼ï¼Œ]', '', text)
    text = re.sub(r'\s+', '', text)
    return text.lower()

def calculate_wer(reference: str, hypothesis: str) -> float:
    """Word Error Rate (WER) è¨ˆç®—"""
    ref_words = list(normalize_text(reference))
    hyp_words = list(normalize_text(hypothesis))
    
    # ç·¨é›†è·é›¢è¨ˆç®—
    d = [[0 for _ in range(len(hyp_words) + 1)] for _ in range(len(ref_words) + 1)]
    
    for i in range(len(ref_words) + 1):
        d[i][0] = i
    for j in range(len(hyp_words) + 1):
        d[0][j] = j
    
    for i in range(1, len(ref_words) + 1):
        for j in range(1, len(hyp_words) + 1):
            if ref_words[i-1] == hyp_words[j-1]:
                d[i][j] = d[i-1][j-1]
            else:
                d[i][j] = min(
                    d[i-1][j] + 1,      # å‰Šé™¤
                    d[i][j-1] + 1,      # æŒ¿å…¥
                    d[i-1][j-1] + 1     # ç½®æ›
                )
    
    # WERè¨ˆç®—
    edit_distance = d[len(ref_words)][len(hyp_words)]
    wer = edit_distance / len(ref_words) if len(ref_words) > 0 else 0
    return wer

def compare_transcriptions(reference_file: str, hypothesis_file: str, verbose: bool = False):
    """éŸ³å£°èªè­˜çµæœã¨æ­£è§£ãƒ‡ãƒ¼ã‚¿ã‚’æ¯”è¼ƒ"""
    print(f"ğŸ“Š éŸ³å£°èªè­˜ç²¾åº¦è©•ä¾¡")
    print(f"æ­£è§£ãƒ‡ãƒ¼ã‚¿: {reference_file}")
    print(f"èªè­˜çµæœ: {hypothesis_file}")
    print("=" * 60)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    ref_data = parse_transcript_file(reference_file)
    hyp_data = parse_transcript_file(hypothesis_file)
    
    print(f"æ­£è§£ãƒ‡ãƒ¼ã‚¿ç™ºè©±æ•°: {len(ref_data)}")
    print(f"èªè­˜çµæœç™ºè©±æ•°: {len(hyp_data)}")
    print("-" * 60)
    
    # æ™‚ç³»åˆ—ã§ãƒãƒƒãƒãƒ³ã‚°
    total_wer = 0
    matched_pairs = 0
    
    for i, (ref_ts, ref_text) in enumerate(ref_data):
        # å¯¾å¿œã™ã‚‹èªè­˜çµæœã‚’æ¤œç´¢ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è¿‘ä¼¼ãƒãƒƒãƒãƒ³ã‚°ï¼‰
        best_match = None
        min_time_diff = float('inf')
        
        for hyp_ts, hyp_text in hyp_data:
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®å·®ã‚’è¨ˆç®—ï¼ˆç§’å˜ä½ï¼‰
            ref_seconds = sum(int(x) * 60 ** (2-i) for i, x in enumerate(ref_ts.split(':')))
            hyp_seconds = sum(int(x) * 60 ** (2-i) for i, x in enumerate(hyp_ts.split(':')))
            time_diff = abs(ref_seconds - hyp_seconds)
            
            if time_diff < min_time_diff:
                min_time_diff = time_diff
                best_match = (hyp_ts, hyp_text)
        
        if best_match and min_time_diff <= 10:  # 10ç§’ä»¥å†…ã®èª¤å·®ãªã‚‰å¯¾å¿œ
            hyp_ts, hyp_text = best_match
            wer = calculate_wer(ref_text, hyp_text)
            total_wer += wer
            matched_pairs += 1
            
            if verbose or wer > 0.3:  # è©³ç´°è¡¨ç¤ºã¾ãŸã¯é«˜ã‚¨ãƒ©ãƒ¼ç‡
                print(f"\n[{ref_ts}] ç™ºè©± {i+1}")
                print(f"æ­£è§£: {ref_text}")
                print(f"èªè­˜: {hyp_text}")
                print(f"WER: {wer:.3f} ({'âœ…' if wer < 0.1 else 'âš ï¸' if wer < 0.3 else 'âŒ'})")
                
                if verbose:
                    # è©³ç´°å·®åˆ†è¡¨ç¤º
                    diff = list(difflib.unified_diff(
                        [ref_text], [hyp_text], 
                        fromfile='æ­£è§£', tofile='èªè­˜', lineterm=''
                    ))
                    if len(diff) > 2:
                        for line in diff[2:]:
                            print(f"  {line}")
        else:
            print(f"\n[{ref_ts}] ç™ºè©± {i+1} - âŒ å¯¾å¿œã™ã‚‹èªè­˜çµæœãªã—")
            print(f"æ­£è§£: {ref_text}")
    
    # çµ±è¨ˆè¡¨ç¤º
    print("\n" + "=" * 60)
    if matched_pairs > 0:
        avg_wer = total_wer / matched_pairs
        accuracy = (1 - avg_wer) * 100
        print(f"ğŸ“ˆ è©•ä¾¡çµæœ:")
        print(f"  ãƒãƒƒãƒã—ãŸç™ºè©±: {matched_pairs}/{len(ref_data)}")
        print(f"  å¹³å‡WER: {avg_wer:.3f}")
        print(f"  èªè­˜ç²¾åº¦: {accuracy:.1f}%")
        
        # è©•ä¾¡åˆ¤å®š
        if accuracy >= 95:
            print(f"  åˆ¤å®š: âœ… å„ªç§€")
        elif accuracy >= 90:
            print(f"  åˆ¤å®š: ğŸŸ¢ è‰¯å¥½")
        elif accuracy >= 80:
            print(f"  åˆ¤å®š: ğŸŸ¡ æ™®é€š")
        else:
            print(f"  åˆ¤å®š: ğŸ”´ è¦æ”¹å–„")
    else:
        print("âŒ ãƒãƒƒãƒã™ã‚‹ç™ºè©±ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

def main():
    parser = argparse.ArgumentParser(description="éŸ³å£°èªè­˜ç²¾åº¦è©•ä¾¡")
    parser.add_argument('reference', help='æ­£è§£ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('hypothesis', help='éŸ³å£°èªè­˜çµæœãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--verbose', '-v', action='store_true', help='è©³ç´°è¡¨ç¤º')
    
    args = parser.parse_args()
    
    if not Path(args.reference).exists():
        print(f"âŒ æ­£è§£ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.reference}")
        return
    
    if not Path(args.hypothesis).exists():
        print(f"âŒ éŸ³å£°èªè­˜çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.hypothesis}")
        return
    
    compare_transcriptions(args.reference, args.hypothesis, args.verbose)

if __name__ == "__main__":
    main() 